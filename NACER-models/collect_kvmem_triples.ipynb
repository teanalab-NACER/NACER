{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ac39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import utils\n",
    "\n",
    "objects_path = 'data/dbpedia-2021-09-kewer/graph/mappingbased-objects_lang=en.ttl'\n",
    "infobox_path = 'data/dbpedia-2021-09-kewer/graph/infobox-properties_lang=en.ttl'\n",
    "max_neighbors = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6b1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_triples(baseline):\n",
    "    to_triples = defaultdict(set)\n",
    "    from_triples = defaultdict(set)\n",
    "    neighbors = defaultdict(set)\n",
    "    i = 0\n",
    "\n",
    "    for ttl_path in [objects_path, infobox_path]:\n",
    "        with open(ttl_path) as input_file:\n",
    "            for line in input_file:\n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "                subj, pred, obj = line.split(maxsplit=2)\n",
    "                if obj.startswith('\"'):\n",
    "                    continue\n",
    "                if pred.lower() in utils.pred_blacklist or re.match(\n",
    "                        r'<http://dbpedia.org/property/([0-9]|footnote|.{1,2}>$)',\n",
    "                        pred):\n",
    "                    continue\n",
    "                obj = obj[:obj.rfind('.')].strip()\n",
    "                if subj in redirects:\n",
    "                    subj = redirects[subj]\n",
    "                if obj in redirects:\n",
    "                    obj = redirects[obj]\n",
    "\n",
    "                if subj in kewer.wv and pred in kewer.wv and obj in kewer.wv:\n",
    "                    to_triples[subj].add((subj, pred, obj))\n",
    "                    neighbors[subj].add(obj)\n",
    "                    if baseline in [3, 4]:\n",
    "                        to_triples[obj].add((obj, pred, subj))\n",
    "                        neighbors[obj].add(subj)\n",
    "                    if baseline in [2, 4]:\n",
    "                        from_triples[obj].add((subj, pred, obj))\n",
    "                        if baseline == 4:\n",
    "                            from_triples[subj].add((obj, pred, subj))\n",
    "                # if subj in kewer.wv and obj in linked_entities_and_previous_answers:\n",
    "                #     neighbors[obj].add(subj)\n",
    "\n",
    "                i += 1\n",
    "                if i % 1000000 == 0:\n",
    "                    print(f'Processed {i} items. Current time: {datetime.now().strftime(\"%H:%M:%S\")}.')\n",
    "\n",
    "    return dict(to_triples), dict(from_triples), dict(neighbors)\n",
    "\n",
    "\n",
    "def find_question_triples(baseline, to_triples, from_triples, neighbors):\n",
    "    question_triples = defaultdict(set)\n",
    "\n",
    "    for question_id, entities in question_entities.items():\n",
    "        for entity, _ in entities:\n",
    "            if entity in to_triples and len(neighbors[entity]) <= max_neighbors:\n",
    "                question_triples[question_id].update(to_triples[entity])\n",
    "\n",
    "    for question_id, answers in previous_answers.items():\n",
    "        for answer in answers:\n",
    "            if answer in to_triples and len(neighbors[answer]) <= max_neighbors:\n",
    "                question_triples[question_id].update(to_triples[answer])\n",
    "\n",
    "    if baseline in [2, 4]:\n",
    "        question_neighbors = defaultdict(set)\n",
    "        for question_id, entities in question_entities.items():\n",
    "            for entity, _ in entities:\n",
    "                if entity in to_triples and len(to_triples[entity]) <= max_neighbors:\n",
    "                    for _, _, obj in to_triples[entity]:\n",
    "                        question_neighbors[question_id].add(obj)\n",
    "\n",
    "        for question_id, answers in previous_answers.items():\n",
    "            for answer in answers:\n",
    "                if answer in to_triples and len(to_triples[answer]) <= max_neighbors:\n",
    "                    for _, _, obj in to_triples[answer]:\n",
    "                        question_neighbors[question_id].add(obj)\n",
    "\n",
    "        for question_id, candidate_entities in question_neighbors.items():\n",
    "            for candidate_entity in candidate_entities:\n",
    "                if len(from_triples[candidate_entity]) <= max_neighbors:\n",
    "                    question_triples[question_id].update(from_triples[candidate_entity])\n",
    "                # else:\n",
    "                #     print(f'{candidate_entity} of question {question_id} has too many from triples')\n",
    "\n",
    "    return question_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c51644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--outfile')\n",
    "parser.add_argument('--baseline', type=int, default=4, choices=range(1, 5),\n",
    "                    help='4 baselines are documented here: https://www.notion.so/Conversational-Entity-Retrieval'\n",
    "                         '-d21dabc7fb3e437f8012894d0cc2a7ce#16ed08f0dcc141a19c03d0fbad6fd7d5')\n",
    "args = parser.parse_args(args=[])\n",
    "if args.outfile is None:\n",
    "    args.outfile = f'data/kvmem-triples/baseline-{args.baseline}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ffc6818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/kvmem-triples/baseline-4.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a02030",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirects = utils.dbpedia_redirects()\n",
    "kewer = utils.load_kewer()\n",
    "question_entities = utils.load_question_entities()\n",
    "previous_answers = utils.load_previous_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91789c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_entities = utils.load_question_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc3a3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83502"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23871cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_answers = utils.load_previous_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f83dd156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52440"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(previous_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc128d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000000 items. Current time: 18:20:10.\n",
      "Processed 2000000 items. Current time: 18:20:22.\n",
      "Processed 3000000 items. Current time: 18:20:34.\n",
      "Processed 4000000 items. Current time: 18:20:49.\n",
      "Processed 5000000 items. Current time: 18:21:04.\n",
      "Processed 6000000 items. Current time: 18:21:21.\n",
      "Processed 7000000 items. Current time: 18:21:31.\n",
      "Processed 8000000 items. Current time: 18:21:50.\n",
      "Processed 9000000 items. Current time: 18:22:00.\n",
      "Processed 10000000 items. Current time: 18:22:10.\n",
      "Processed 11000000 items. Current time: 18:22:33.\n",
      "Processed 12000000 items. Current time: 18:22:44.\n",
      "Processed 13000000 items. Current time: 18:22:53.\n",
      "Processed 14000000 items. Current time: 18:23:03.\n",
      "Processed 15000000 items. Current time: 18:23:26.\n",
      "Processed 16000000 items. Current time: 18:23:36.\n",
      "Processed 17000000 items. Current time: 18:23:46.\n",
      "Processed 18000000 items. Current time: 18:23:57.\n",
      "Processed 19000000 items. Current time: 18:24:07.\n",
      "Processed 20000000 items. Current time: 18:24:32.\n",
      "Processed 21000000 items. Current time: 18:24:42.\n",
      "Processed 22000000 items. Current time: 18:24:54.\n",
      "Processed 23000000 items. Current time: 18:25:10.\n",
      "Processed 24000000 items. Current time: 18:25:25.\n",
      "Processed 25000000 items. Current time: 18:25:40.\n",
      "Processed 26000000 items. Current time: 18:25:55.\n",
      "Processed 27000000 items. Current time: 18:26:09.\n",
      "Processed 28000000 items. Current time: 18:26:23.\n",
      "Processed 29000000 items. Current time: 18:26:38.\n",
      "Processed 30000000 items. Current time: 18:26:52.\n",
      "Processed 31000000 items. Current time: 18:27:06.\n",
      "Processed 32000000 items. Current time: 18:27:21.\n",
      "Processed 33000000 items. Current time: 18:27:35.\n",
      "Processed 34000000 items. Current time: 18:27:50.\n",
      "Processed 35000000 items. Current time: 18:28:04.\n",
      "Processed 36000000 items. Current time: 18:28:53.\n",
      "Processed 37000000 items. Current time: 18:29:07.\n",
      "Processed 38000000 items. Current time: 18:29:22.\n",
      "Processed 39000000 items. Current time: 18:29:37.\n",
      "Processed 40000000 items. Current time: 18:29:52.\n",
      "Processed 41000000 items. Current time: 18:30:07.\n",
      "Processed 42000000 items. Current time: 18:30:23.\n",
      "Processed 43000000 items. Current time: 18:30:38.\n",
      "Processed 44000000 items. Current time: 18:30:52.\n",
      "Processed 45000000 items. Current time: 18:31:07.\n",
      "Done with the triples.\n"
     ]
    }
   ],
   "source": [
    "to_triples, from_triples, neighbors = find_triples(args.baseline)\n",
    "print('Done with the triples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d1d76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with the question triples.\n"
     ]
    }
   ],
   "source": [
    "question_triples = find_question_triples(args.baseline, to_triples, from_triples, neighbors)\n",
    "print('Done with the question triples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7225fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_triples = {question_id: sorted(triples) for question_id, triples in question_triples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f893afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.outfile, 'w') as f:\n",
    "    json.dump(question_triples, f, sort_keys=False, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58be895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
