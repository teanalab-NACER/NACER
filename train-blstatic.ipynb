{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eaa9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import utils\n",
    "from collections import defaultdict\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61524112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epochs=2, features_mask=None, gpu=0, hidden='20,10', interaction='mult', loadmodel=None, qemb='blstatic', same_w=True, savemodel='models/model-mult-same-blstatic.pt')\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--gpu', type=int, default=0, help=\"GPU device ID. Use -1 for CPU training\")\n",
    "parser.add_argument('--epochs', type=int, default=2, help=\"Number of training epochs\")\n",
    "parser.add_argument('--hidden', type=str, default='20,10', help=\"Sized of hidden layers, comma-separated\")\n",
    "utils.add_bool_arg(parser, 'same-w', True)  # use the same matrix W for all features\n",
    "parser.add_argument('--interaction', default='mult', choices=['mult', 'add', 'dot'],\n",
    "                    help=\"Interaction function to use\")\n",
    "parser.add_argument('--qemb', default='blstatic', choices=['kewer', 'blstatic', 'bldynamic'],\n",
    "                    help=\"How to embed question text. \"\n",
    "                         \"kewer: mean of KEWER embeddings of tokens and linked entities, \"\n",
    "                         \"bldynamic: Bi-LSTM embedding trained as part of the model, \"\n",
    "                         \"blstatic: Static pre-trained Bi-LSTM embedding\")\n",
    "parser.add_argument('--features-mask', nargs='+', type=int, help=\"Features mask for feature ablation study\")\n",
    "parser.add_argument('--savemodel', default='models/model-mult-same-blstatic.pt', help=\"Path to save the model\")\n",
    "parser.add_argument('--loadmodel', help='Load this model checkpoint before training')\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f3b11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loadmodel:\n",
    "    checkpoint = torch.load(args.loadmodel)\n",
    "    print(checkpoint['args'])\n",
    "else:\n",
    "    checkpoint = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edfeb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_inputs = utils.load_feature_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47668f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "kewer = utils.load_kewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a921249",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_probs = None\n",
    "question_entities = None\n",
    "train_question_embeddings = None\n",
    "dev_question_embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a74d2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.qemb == 'kewer':\n",
    "    word_probs = utils.load_word_probs()\n",
    "    question_entities = utils.load_question_entities()\n",
    "elif args.qemb == 'blstatic':\n",
    "    train_question_embeddings = utils.load_question_embeddings('train')\n",
    "    dev_question_embeddings = utils.load_question_embeddings('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "347f5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_question_set(args, qblink_split, overlap_features, feature_inputs, question_embeddings, kewer, word_probs,\n",
    "                      question_entities):\n",
    "    question_set = []\n",
    "    for sequence in qblink_split:\n",
    "        for question in ['q1', 'q2', 'q3']:\n",
    "            question_id = str(sequence[question]['t_id'])\n",
    "            question_text = sequence[question]['quetsion_text']\n",
    "            target_entity = f\"<http://dbpedia.org/resource/{sequence[question]['wiki_page']}>\"\n",
    "            if question_id in overlap_features:\n",
    "\n",
    "                if question == 'q1':\n",
    "                    previous_answer = None\n",
    "                elif question == 'q2':\n",
    "                    previous_answer = f\"<http://dbpedia.org/resource/{sequence['q1']['wiki_page']}>\"\n",
    "                elif question == 'q3':\n",
    "                    previous_answer = f\"<http://dbpedia.org/resource/{sequence['q2']['wiki_page']}>\"\n",
    "                if previous_answer is not None and previous_answer in kewer.wv:\n",
    "                    previous_answer_embedding = kewer.wv[previous_answer].copy()\n",
    "                else:\n",
    "                    previous_answer_embedding = np.zeros(kewer.wv.vector_size, dtype=np.float32)\n",
    "\n",
    "                overlap_feature_array = []\n",
    "                feature_input_arrays = {\n",
    "                    'p': [],\n",
    "                    'lit': [],\n",
    "                    'cat': [],\n",
    "                    'ent': [],\n",
    "                    's': []\n",
    "                }\n",
    "                for i, (entity, entity_overlap_features) in enumerate(overlap_features[question_id].items()):\n",
    "                    assert entity in feature_inputs\n",
    "                    overlap_feature_array.append(entity_overlap_features)\n",
    "                    for feature_type in ['p', 'lit', 'cat', 'ent']:\n",
    "                        if feature_inputs[entity]['counts'][feature_type] > 0:\n",
    "                            feature_input_arrays[feature_type].append(\n",
    "                                feature_inputs[entity]['feature_inputs'][feature_type] /\n",
    "                                feature_inputs[entity]['counts'][feature_type])\n",
    "                        else:\n",
    "                            assert (feature_inputs[entity]['feature_inputs'][feature_type] == 0).all()\n",
    "                            feature_input_arrays[feature_type].append(\n",
    "                                feature_inputs[entity]['feature_inputs'][feature_type])\n",
    "                    feature_input_arrays['s'].append((feature_inputs[entity]['feature_inputs']['lit'] +\n",
    "                                                      feature_inputs[entity]['feature_inputs']['cat'] +\n",
    "                                                      feature_inputs[entity]['feature_inputs']['ent']) / (\n",
    "                                                             feature_inputs[entity]['counts']['lit'] +\n",
    "                                                             feature_inputs[entity]['counts']['cat'] +\n",
    "                                                             feature_inputs[entity]['counts']['ent']))\n",
    "                    if entity == target_entity:\n",
    "                        target_index = i\n",
    "                \n",
    "                question_set_item = {\n",
    "                    'overlap_features': np.array(overlap_feature_array, dtype=np.float32),\n",
    "                    'p_inputs': np.array(feature_input_arrays['p'], dtype=np.float32),\n",
    "                    'lit_inputs': np.array(feature_input_arrays['lit'], dtype=np.float32),\n",
    "                    'cat_inputs': np.array(feature_input_arrays['cat'], dtype=np.float32),\n",
    "                    'ent_inputs': np.array(feature_input_arrays['ent'], dtype=np.float32),\n",
    "                    's_inputs': np.array(feature_input_arrays['s'], dtype=np.float32),\n",
    "                    'previous_answer_embedding': previous_answer_embedding,\n",
    "                    'target_index': target_index\n",
    "                }\n",
    "                \n",
    "                question_set_item['overlap_features'] = np.pad(question_set_item['overlap_features'],((0,512-question_set_item['overlap_features'].shape[0]),(0,0)), \n",
    "                                                               'constant', constant_values=(0,0)) \n",
    "                \n",
    "                question_set_item['p_inputs'] = np.pad(question_set_item['p_inputs'],((0,512-question_set_item['p_inputs'].shape[0]),(0,0)), \n",
    "                                                       'constant', constant_values=(0,0))\n",
    "                \n",
    "                question_set_item['lit_inputs'] = np.pad(question_set_item['lit_inputs'],((0,512-question_set_item['lit_inputs'].shape[0]),(0,0)), \n",
    "                                                         'constant', constant_values=(0,0))\n",
    "                \n",
    "                question_set_item['cat_inputs'] = np.pad(question_set_item['cat_inputs'],((0,512-question_set_item['cat_inputs'].shape[0]),(0,0)), \n",
    "                                                         'constant', constant_values=(0,0))\n",
    "                \n",
    "                question_set_item['ent_inputs'] = np.pad(question_set_item['ent_inputs'],((0,512-question_set_item['ent_inputs'].shape[0]),(0,0)), \n",
    "                                                         'constant', constant_values=(0,0))\n",
    "                \n",
    "                question_set_item['s_inputs'] = np.pad(question_set_item['s_inputs'],((0,512-question_set_item['s_inputs'].shape[0]),(0,0)), \n",
    "                                                       'constant', constant_values=(0,0))\n",
    "                    \n",
    "                \n",
    "                if args.qemb == 'kewer':\n",
    "                    question_set_item['question_embedding'] = utils.embed_question(question_text, kewer.wv, word_probs,\n",
    "                                                                                   question_entities[question_id])\n",
    "                elif args.qemb == 'blstatic':\n",
    "                    question_set_item['question_embedding'] = utils.get_question_embedding(question_embeddings,\n",
    "                                                                                           int(question_id))\n",
    "                elif args.qemb == 'bldynamic':\n",
    "                    question_set_item['question'] = question_text\n",
    "\n",
    "                question_set.append(question_set_item)\n",
    "    return question_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "608ceac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 14586\n"
     ]
    }
   ],
   "source": [
    "train_split = utils.load_qblink_split('train')\n",
    "train_overlap_features = utils.load_overlap_features('train')\n",
    "train_set = load_question_set(args, train_split, train_overlap_features, feature_inputs, train_question_embeddings,\n",
    "                              kewer, word_probs, question_entities)\n",
    "print('Training examples:', len(train_set))\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d38c3132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev examples: 1111\n"
     ]
    }
   ],
   "source": [
    "dev_split = utils.load_qblink_split('dev')\n",
    "dev_overlap_features = utils.load_overlap_features('dev')\n",
    "dev_set = load_question_set(args, dev_split, dev_overlap_features, feature_inputs, dev_question_embeddings, kewer,\n",
    "                            word_probs, question_entities)\n",
    "print('Dev examples:', len(dev_set))\n",
    "dev_loader = DataLoader(dev_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40cc534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.gpu >= 0:\n",
    "    device = torch.device('cuda:%d' % args.gpu)\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8bb0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, device, trainloader, devloader, checkpoint=None):\n",
    "    train_samples = len(trainloader)\n",
    "    dev_samples = len(devloader)\n",
    "\n",
    "    if checkpoint:\n",
    "        model_args = checkpoint['args']\n",
    "        model = utils.init_model_from_args(model_args)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        qemb = model_args.qemb\n",
    "        interaction = model_args.interaction\n",
    "    else:\n",
    "        model = utils.init_model_from_args(args)\n",
    "        qemb = args.qemb\n",
    "        interaction = args.interaction\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    if args.features_mask:\n",
    "        for name, child in model.named_parameters():\n",
    "            if 'model_cosine' not in name:\n",
    "                child.requires_grad = False\n",
    "        features_mask = torch.tensor(args.features_mask).to(device)\n",
    "    else:\n",
    "        features_mask = None\n",
    "\n",
    "    if interaction == 'dot':\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    if checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if checkpoint and not args.features_mask:\n",
    "        best_epoch = checkpoint['epoch']\n",
    "        best_dev_loss = checkpoint['best_dev_loss']\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "    else:\n",
    "        best_epoch = -1\n",
    "        best_dev_loss = float('inf')\n",
    "        start_epoch = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        train_epoch_loss = 0.0\n",
    "        model.train()\n",
    "        epoch_start_time = time.time()\n",
    "        for sample in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            overlap_features = sample['overlap_features'].to(device)\n",
    "            p_inputs = sample['p_inputs'].to(device)\n",
    "            lit_inputs = sample['lit_inputs'].to(device)\n",
    "            cat_inputs = sample['cat_inputs'].to(device)\n",
    "            ent_inputs = sample['ent_inputs'].to(device)\n",
    "            s_inputs = sample['s_inputs'].to(device)\n",
    "            previous_answer_embedding = sample['previous_answer_embedding'].to(device)\n",
    "            previous_answer_embedding = previous_answer_embedding.unsqueeze(dim = 1)\n",
    "            target = sample['target_index'].to(device)\n",
    "            \n",
    "            if qemb == 'kewer' or qemb == 'blstatic':\n",
    "                question_embedding = sample['question_embedding'].to(device)\n",
    "                question_embedding = question_embedding.unsqueeze(dim = 1)\n",
    "                scores = model(overlap_features, p_inputs, lit_inputs, cat_inputs, ent_inputs, s_inputs,\n",
    "                               question_embedding, previous_answer_embedding, features_mask)\n",
    "            else:  # bldynamic\n",
    "                question = sample['question'][0]\n",
    "                scores = model(overlap_features, p_inputs, lit_inputs, cat_inputs, ent_inputs, s_inputs,\n",
    "                               question, previous_answer_embedding, features_mask)\n",
    "            loss = criterion(scores, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_epoch_loss += loss.item()\n",
    "\n",
    "        dev_epoch_loss = 0.0\n",
    "        model.eval()\n",
    "        for sample in devloader:\n",
    "            overlap_features = sample['overlap_features'].to(device)\n",
    "            p_inputs = sample['p_inputs'].to(device)\n",
    "            lit_inputs = sample['lit_inputs'].to(device)\n",
    "            cat_inputs = sample['cat_inputs'].to(device)\n",
    "            ent_inputs = sample['ent_inputs'].to(device)\n",
    "            s_inputs = sample['s_inputs'].to(device)\n",
    "            previous_answer_embedding = sample['previous_answer_embedding'].to(device)\n",
    "            previous_answer_embedding = previous_answer_embedding.unsqueeze(dim = 1)\n",
    "            target = sample['target_index'].to(device)\n",
    "            if qemb == 'kewer' or qemb == 'blstatic':\n",
    "                question_embedding = sample['question_embedding'].to(device)\n",
    "                question_embedding = question_embedding.unsqueeze(dim = 1)\n",
    "                scores = model(overlap_features, p_inputs, lit_inputs, cat_inputs, ent_inputs, s_inputs,\n",
    "                               question_embedding, previous_answer_embedding, features_mask)\n",
    "            else:  # bldynamic\n",
    "                question = sample['question'][0]\n",
    "                scores = model(overlap_features, p_inputs, lit_inputs, cat_inputs, ent_inputs, s_inputs,\n",
    "                               question, previous_answer_embedding, features_mask)\n",
    "            loss = criterion(scores, target)\n",
    "            dev_epoch_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch} train loss: {train_epoch_loss / train_samples:.4f}, ' +\n",
    "              f'dev loss: {dev_epoch_loss / dev_samples:.4f}. Took {time.time() - epoch_start_time:.2f} seconds. '\n",
    "              f'Total time: {(time.time() - start_time) / (60 * 60):.2f} hours.')\n",
    "        if dev_epoch_loss / dev_samples < best_dev_loss:\n",
    "            best_dev_loss = dev_epoch_loss / dev_samples\n",
    "            best_epoch = epoch\n",
    "            print(f'Saving model {args.savemodel}...')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_dev_loss': best_dev_loss,\n",
    "                'args': args\n",
    "            }, args.savemodel)\n",
    "    print(f'Best dev loss {best_dev_loss} on was achieved on epoch {best_epoch}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ee23684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 5.9386, dev loss: 5.4020. Took 59.53 seconds. Total time: 0.14 hours.\n",
      "Saving model models/model-mult-same-blstatic.pt...\n",
      "Epoch 1 train loss: 4.7597, dev loss: 4.2911. Took 42.82 seconds. Total time: 0.15 hours.\n",
      "Saving model models/model-mult-same-blstatic.pt...\n",
      "Best dev loss 4.291075801849365 on was achieved on epoch 1.\n"
     ]
    }
   ],
   "source": [
    "train(args, device, train_loader, dev_loader, checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
